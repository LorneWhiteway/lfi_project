#!/bin/tcsh

#SBATCH -p GPU
#requesting one node
#SBATCH -N1
#requesting 1 cpu
#SBATCH -n1
#requesting 1 GPU
#        If you want to insist on using the XX GPU (XX=v100 or k80), then set the next command to
#        #SBATCH --gres=gpu:XX:1
#        If you are indifferent then set it to
#        #SBATCH --gres=gpu:1
#        Beware - also need to change directory for executable (in the main body of this script).
#SBATCH --gres=gpu:v100:1
#SBATCH --job-name=cuda_test
#SBATCH --mail-user=lorne.whiteway@star.ucl.ac.uk
#SBATCH --mail-type=END,FAIL
#SBATCH --time=16-00:00:00
#SBATCH --mem=128000


## Call this job script using syntax like this:
## sbatch cuda_job_script

## To go to the GPU node, do:
## srun -p GPU --gres=gpu:XX:1 --pty tcsh
## where XX=v100 or k80, depending on which GPU you wish to go to.
## From there you might want to do:
## cd /state/partition1/ucapwhi/lfi_project/experiments

# Load the module files
source /share/splinter/ucapwhi/lfi_project/set_environment.csh USE
cd /share/splinter/ucapwhi/lfi_project/cuda_test
/share/splinter/ucapwhi/lfi_project/cuda_test/cuda_test >& /share/splinter/ucapwhi/lfi_project/cuda_test/output.txt



